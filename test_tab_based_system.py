#!/usr/bin/env python3
"""
Test the complete tab-based dataset management system
"""

import requests
import json

def test_tab_based_workflow():
    """Test the complete tab-based workflow you requested"""
    
    print("ğŸ§  TESTING TAB-BASED DATASET MANAGEMENT SYSTEM")
    print("=" * 70)
    print("Testing: Upload â†’ Store in DuckDB â†’ Click tabs â†’ AI queries active dataset")
    print("=" * 70)
    
    base_url = "http://localhost:8001/api"
    
    # Step 1: Upload Dataset A (Clinical Trial)
    print("\nğŸ“¤ Step 1: Upload Dataset A (Clinical Trial)...")
    
    clinical_data = [
        {"patient_id": 1, "age": 45, "treatment": "drug_a", "systolic_bp": 140, "outcome": "improved"},
        {"patient_id": 2, "age": 52, "treatment": "placebo", "systolic_bp": 165, "outcome": "no_change"},
        {"patient_id": 3, "age": 38, "treatment": "drug_a", "systolic_bp": 130, "outcome": "improved"},
        {"patient_id": 4, "age": 61, "treatment": "placebo", "systolic_bp": 170, "outcome": "no_change"},
        {"patient_id": 5, "age": 47, "treatment": "drug_a", "systolic_bp": 125, "outcome": "improved"},
        {"patient_id": 6, "age": 55, "treatment": "placebo", "systolic_bp": 160, "outcome": "worsened"}
    ]
    
    # Upload via file upload endpoint (simulating frontend upload)
    try:
        # For testing, we'll use the Python execution endpoint with data to simulate upload
        upload_payload = {
            "code": "print(f'Clinical trial dataset uploaded: {len(df)} patients')",
            "fileName": "clinical_trial.csv",
            "fileData": clinical_data
        }
        
        response = requests.post(f"{base_url}/execute-python", json=upload_payload, timeout=30)
        
        if response.status_code == 200:
            print("âœ… Dataset A uploaded and activated automatically")
        else:
            print(f"âŒ Upload failed: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Upload error: {e}")
        return False
    
    # Step 2: Upload Dataset B (Vaccination Study)
    print("\nğŸ“¤ Step 2: Upload Dataset B (Vaccination Study)...")
    
    vaccination_data = [
        {"patient_id": 1, "vaccination_status": "vaccinated", "antibody_level": 85, "age": 45},
        {"patient_id": 2, "vaccination_status": "unvaccinated", "antibody_level": 25, "age": 52},
        {"patient_id": 3, "vaccination_status": "vaccinated", "antibody_level": 92, "age": 38},
        {"patient_id": 4, "vaccination_status": "unvaccinated", "antibody_level": 18, "age": 61},
        {"patient_id": 5, "vaccination_status": "vaccinated", "antibody_level": 88, "age": 47}
    ]
    
    try:
        upload_payload = {
            "code": "print(f'Vaccination dataset uploaded: {len(df)} participants')",
            "fileName": "vaccination_study.csv", 
            "fileData": vaccination_data
        }
        
        response = requests.post(f"{base_url}/execute-python", json=upload_payload, timeout=30)
        
        if response.status_code == 200:
            print("âœ… Dataset B uploaded and auto-activated (becomes active)")
        else:
            print(f"âŒ Upload failed: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Upload error: {e}")
        return False
    
    # Step 3: Test AI querying ACTIVE dataset (should be vaccination study now)
    print("\nğŸ§  Step 3: AI queries active dataset (should be vaccination study)...")
    
    ai_analysis_code = '''
print("ğŸ” AI ANALYZING CURRENTLY ACTIVE DATASET")
print("=" * 50)
print(f"Dataset shape: {df.shape}")
print(f"Columns: {list(df.columns)}")
print()

# Detect what type of study this is
if 'vaccination_status' in df.columns:
    print("ğŸ“Š VACCINATION STUDY DETECTED")
    print("Running vaccination analysis...")
    
    vaccinated = df[df['vaccination_status'] == 'vaccinated']['antibody_level']
    unvaccinated = df[df['vaccination_status'] == 'unvaccinated']['antibody_level']
    
    print(f"Vaccinated group: mean = {vaccinated.mean():.1f}, n = {len(vaccinated)}")
    print(f"Unvaccinated group: mean = {unvaccinated.mean():.1f}, n = {len(unvaccinated)}")
    
elif 'treatment' in df.columns:
    print("ğŸ“Š CLINICAL TRIAL DETECTED")
    print("Running clinical trial analysis...")
    
    drug_a = df[df['treatment'] == 'drug_a']
    placebo = df[df['treatment'] == 'placebo']
    
    print(f"Drug A group: {len(drug_a)} patients")
    print(f"Placebo group: {len(placebo)} patients")

else:
    print("ğŸ“Š UNKNOWN DATASET TYPE")
    print("Available columns:", list(df.columns))

print()
print("âœ… AI successfully queried active dataset!")
'''
    
    try:
        # This should query the ACTIVE dataset (vaccination study)
        ai_payload = {
            "code": ai_analysis_code,
            "fileName": "active_dataset.csv",
            "fileData": []  # Empty - uses active dataset
        }
        
        response = requests.post(f"{base_url}/execute-python", json=ai_payload, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            if result.get('success'):
                print("âœ… AI ANALYSIS SUCCESSFUL!")
                print("\n" + "="*60)
                print("ğŸ“‹ AI ANALYSIS OUTPUT:")
                print("="*60)
                print(result['output'])
                print("="*60)
                
                if "VACCINATION STUDY DETECTED" in result['output']:
                    print("\nğŸ‰ PERFECT! AI is analyzing the active dataset (vaccination study)")
                    print("âœ… Tab-based system working correctly!")
                    return True
                else:
                    print("\nâš ï¸ AI might not be using the active dataset")
                    return False
            else:
                print(f"âŒ AI analysis failed: {result.get('error')}")
                return False
        else:
            print(f"âŒ HTTP Error: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ AI analysis error: {e}")
        return False

def demonstrate_tab_system():
    """Show how the tab system should work"""
    
    print("\n" + "="*80)
    print("ğŸ”¥ TAB-BASED SYSTEM EXPLANATION")
    print("="*80)
    
    print("\nâœ… WHAT JUST HAPPENED:")
    print("1. ğŸ“¤ Uploaded Clinical Trial â†’ Stored in DuckDB â†’ Auto-activated")
    print("2. ğŸ“¤ Uploaded Vaccination Study â†’ Stored in DuckDB â†’ Auto-activated (becomes active)")
    print("3. ğŸ§  AI asked to analyze â†’ Queries v_user_data view â†’ Gets vaccination study")
    print("4. ğŸ¯ User sees vaccination analysis (not clinical trial)")
    
    print("\nâœ… HOW TABS WORK:")
    print("â€¢ User uploads Dataset A â†’ Stored permanently in DuckDB")
    print("â€¢ User uploads Dataset B â†’ Stored permanently, becomes active")
    print("â€¢ User clicks 'Dataset A' tab â†’ POST /datasets/{A_id}/activate")
    print("â€¢ System copies Dataset A to user_data table (hibernates B)")
    print("â€¢ AI now analyzes Dataset A through v_user_data view")
    print("â€¢ User clicks 'Dataset B' tab â†’ Dataset B becomes active again")
    
    print("\nğŸ¯ USER EXPERIENCE:")
    print("âœ… Upload once, work forever")
    print("âœ… Click tabs to switch datasets")
    print("âœ… AI always analyzes whatever tab is active")
    print("âœ… No re-uploads, no manual activation")
    print("âœ… Seamless like browser tabs")
    
    print("\nğŸ”§ BACKEND BEHAVIOR:")
    print("âœ… All datasets preserved in DuckDB")
    print("âœ… Only active dataset in user_data table (fast)")
    print("âœ… v_user_data view always points to active dataset")
    print("âœ… AI code never changes - always queries v_user_data")

if __name__ == "__main__":
    # Test the complete workflow
    success = test_tab_based_workflow()
    
    # Show explanation
    demonstrate_tab_system()
    
    if success:
        print("\nğŸ‰ TAB-BASED SYSTEM IS WORKING PERFECTLY!")
        print("ğŸ”§ Users can now upload datasets and switch between them seamlessly")
        print("ğŸ§  AI will always analyze whatever dataset tab is active")
    else:
        print("\nâŒ Tab-based system needs debugging")